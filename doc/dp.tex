\documentclass[english]{fitprj}
%\documentclass[a4paper,11pt]{report}
%\usepackage{a4wide}
\usepackage[latin2]{inputenc}
\usepackage[
  bookmarks=true,
  bookmarksopen=true,
  bookmarksopenlevel=2,
  pdfhighlight=/I,
  pdftitle=Construction\ of\ GNU\ Compiler\ Collection\ Frontend,
  pdfauthor=Petr\ Machata,
  pdfstartview=FitH,
  pdfborder={0 0 0}
  ]{hyperref}
\usepackage{subscript}
\pagestyle{empty}
\topmargin 0in

\date{January 3rd}
\setyear{2007}
\author{Bc. Petr Machata}
\title{Construction of GNU Compiler Collection Front End}
\FITproject{SP}

\def\Algol{{\sc Algol}\space}

\edeclaration{ I hereby declare that this work has been created by me,
  under the supervision of Milo¹ Eysselt, and under technical lead of
  Luká¹ Szemla.  All information resources that I have used are
  properly cited.  }

\acknowledgements{ I owe thanks for patience and advices to the
  thesis' technical adviser, Luká¹ Szemla, who was bombarded by my
  status reports monthly; and Professor Jan van Katwijk of Delft
  University of Technology, for advices regarding odds and ends of
  \Algol 60. }


\fitabstract{The Abstract}

\keywords{GCC, GNU Compiler Collection, frontend, front end, Algol 60, compiler}

\fitabstractCZ{Abstrakt}

\keywordsCZ{GCC, GNU Compiler Collection, pøední èást, Algol 60, kompilátor}

\begin{document}

\maketitle
% tady bude zadani
\grantrights
\abstractkeywordsCZ
\abstractkeywords
\FITstart

% for various computer-related terms
\def\literal#1{{\sffamily{}#1}}
% functions names
\def\function#1{{\sffamily{}#1}}
% file names
\def\file#1{{\sffamily{}#1}}
% commandline options
\def\option#1{{\sffamily{}#1}}
% variables, types, and similar
\def\variable#1{{\sffamily{}#1}}

% program listings
\def\program#1{{\sffamily\begin{tabbing}#1\end{tabbing}}}
% keywords in program listings
\def\keyw#1{{\sffamily\bfseries {#1}}}
% indentation
\def\ind{\hspace{0.5cm}}

\def\note#1{{{\it Note.\space}#1}}
\def\output#1{{\ttfamily\begin{tabbing}#1\end{tabbing}}}

\def\term#1{{\it #1}}

\def\NWY{(\note{This is not written yet.  It's in plan for
    final thesis.})}

% ====================================================================

\chapter{Introduction}

Describe what this thesis is about, summarize chapters, provide
insight to how to read it.

In this work, I will refer to myself as ``me'', and a reader as
``you''.


% ====================================================================

\chapter{Why GCC, Why Now}

When facing a~task of engineering a processor
\footnote{In a general sense of a tool that allows direct or indirect
  execution of a program in a given language.} of a given language,
you have several options.

\section{Language Processors Breakdown}

You could write an interpreter, a tool that, given a~program, emulates
its actions token by token, possibly using some form of
compilation into intermediate code.  Interpreter has the advantage of
being rather simple to write.  And if the language still isn't sorted
out completely, it will be simple to adjust the processor.

You could write a compiler that emits other high-level language, such
as C.  Compilation via C is quite popular, but it has drawbacks.
E.g. programs in C will contain artifacts introduced during the
compilation, and those will be visible in debugger.  C may not support
all the necessary constructs that your language needs, and you may
have to use an even higher-level language.  You will typically have to
give artificial names to various thunks of code, and mangle program
identifiers.  On the other hand, C is well understood, with
ubiquitous compilers, and tons of documentation.

Another option is producing virtual machine instructions, such as JVM
or CLR.  This can be advantageous, if you can count on having the
target machine on binary host site.  Virtual machines typically do
just in time compilation, so you can experience near-native speed of
programs.  And they can be ported to several platforms, which means
your compiler will be portable for free.

\section{Processing With GCC}

This thesis describes yet another option: writing the processor as a
part of a well known compiler suite, GCC.

Crafting GCC front ends used to be hard.  One had to understand quirks
of RTL, GCC's intermediate language, which was neither easy, nor
high-level.  But things changed: GCC team took tree language used as
an AST representation in C and C++ front ends, and generalized it into
an official intermediate language called GENERIC.  Work with GENERIC
is rather easy\cite{LJ:2005:Tromey}, on par, I'd say, with emitting C.
Unlike C, there are all GCC bells and whistles: attributes, inline
assembly, OpenMP.  So it's very powerful platform, compared to C.

Unlike C, however, the documentation is rather thin.  Quite often I
found myself scanning through other front ends in hunt for particular
usage of some feature.  Quite often GCC died on me with assertion
error, and I had to look up what went wrong, and figure out why.  This
is actually easier than it sounds, but the fact is, GCC would benefit
from better documentation.

GCC is work in progress.  For some twenty years as of now.  Things change.
If you won't get your front end into GCC trunk, you will have to deal
with those changes yourself.  And as far as I know, new languages are
not exactly the priority of GCC team, supposedly for exactly the
reason that they would have to maintain them.  It would have to be
very high-impact language for that to happen.  If you won't carry your
compiler forward, it will become irrelevant as time passes.  Just as
are GCC-2.9x front ends irrelevant today, and just as GCC-3.x front ends
will become one day.

Given GCC's strong C heritage, it's still best fit for compilation of
C-like languages.  Currently the GCC family contains C, C++, their
Objective variants, Java, FORTRAN, and Ada.  Those are all rather
C-like languages.  I can imagine compiling something like Python
through GCC, and Mercury, a declarative logic/functional language was
implemented as GCC front end.  But still the best match will be for
imperative C-like languages.

Last but not least, GCC is a mature, even if underdocumented compiler.
Big companies depend on GCC, on both the vendor and the consumer
sides.  It is ported to a huge number of platforms, and has the
necessary drive and impact.  Lots of people know how to use it, build
it, package it, distribute it, and that means lots of people will know
how to work with your front end from the day one.  This is very
important.  Clever usage of GCC features will make your processor
another option for wide range of tasks, from parallel to systems
programming.

\section{What's Ahead}

I have written an \Algol 60 \cite{TR:ALGOL60} front end for
GCC\footnote{\url{http://projects.almad.net/gcc-algol}} to get myself
familiar with the platform.  I was expecting days\footnote{Or rather
  nights. With lots of tea.} spent in GCC's internals, digging in code
knee deep.  Much to my surprise, no such thing happened.  I had my
share of cursing, but overall I was pleasantly surprised.  I doubt
going via C would make the work significantly easier.

What's ahead is description of my experience with development of
\Algol 60 front end.  It's a mix of things from GCC Internals
documentation \cite{TR:GCCInt}, things cut'n'pasted from other
people's code and later analyzed, and things either found in GCC
comments or tried by chance and found to work, all wrapped up and
delivered as a continuous, and hopefully coherent text.


% ====================================================================

\chapter{GCC Architecture}

GCC can translate from variety of source languages into variety of
assemblers.  With one command, decorated with various flags, it's
possible to do preprocessing, compilation, assembly and linking.  How
does it achieve this?

In following sections, we delve into successively deeper levels of
overall GCC architecture.

\section{Compilation Driver and Compiler Proper}

On the outermost level, GCC is divided into a \term{compilation
  driver}, and a \term{compiler proper}.  Besides this, GCC uses
several host tool chain components, an assembler and linker.

Compilation driver is a user-interfacing application.  It knows about
all languages that GCC supports.  Given a source file, it can guess
what to do based on file's suffix.  Then it launches various other
tools, most prominently compiler proper, but also preprocessor,
assembler, and, eventually, linker.

Whole compilation works as a pipeline on an application level.  After
optional preprocessing, the source file is fed into compiler proper,
that emits assembly.  This is then assembled into object file.
Finally, object file is handed over to linker to produce final
executable.  This process is managed by compilation driver.  Depending
on command line switches in effect it can be cut short in any of the
stages: after preprocessing (\option{-E}), after compilation
(\option{-S}), and after assembly (\option{-c}).

From our standpoint, the critical component is the compiler proper.
There is one such component for each language, each in separated
executable binary.  You can run the binary yourself if you so wish,
just as driver does.  Let's look at that component closer in next
section.

\section{Front End, Middle End, and Back End}

The compiler proper itself is composed of three components: a
\term{front end}, a \term{back end}, and a \term{middle end}.  While
the front end is suited specifically to each language, the two other
ends are the same in all various compiler propers.  Front end is the
part that encapsulates all the logic special to your language.

Just like the compilation process done by the driver, the compilation
of a source file can be viewed as a pipeline that converts one program
representation into another.  Source code enters the front end and
flows through the pipeline, being converted at each stage into
successively lower-level representation forms until final code
generation in the form of assembly code \cite{LDS:2006:Novillo}.

There are two intermediate languages that are used on the interfaces
between the three GCC's ends.  The higher level one, used between
front end and middle end, is called \term{GENERIC}.  The lower level
one, used between middle end and back end, is called RTL, or Register
Transfer Language.  Both middle end and back end do various
optimizations on their intermediate representation before they turn it
into yet lower level one.

Both interfaces mentioned are {\em unidirectional}: front end feeds
GENERIC into middle end, middle end feeds RTL into back end.  But
sometimes the other direction is also necessary.  For example, during
alias analysis, middle end has to know whether two objects of
different data types may occupy the same memory location \cite{LDS:2006:Novillo}.
Each
language has its own rules for that, and front end is the place where
language-dependent things happen.  For this purpose, GCC has a
mechanism of \term{language hooks} or \term{langhooks}, which provide
a way to front end's participation in lower layers of compilation
process.

The goal of front end is to analyze source program, and ensure all
types are correct and all constraints required by the language
definition hold.  If everything is OK, it has to provide GENERIC
representation of the program.  For this reason, a bulk of this thesis
deals with GENERIC.  You don't have to know anything about RTL to
write front end---at least I don't.

\section{GENERIC and GIMPLE}

The intermediate form that is important to us is called GENERIC.  From
expressiveness point of view, it's similar to C.  From notation point of
view, it's similar to Lisp.  GENERIC is capable of representing whole
functions, i.e. it supports everything there is to represent in a
typical C function: variables, loops, conditionals, function calls,
etc.

GENERIC is a tree language (thus the Lisp qualities).  As any well
behaving tree, it's recursive in nature, having both internal and leaf
nodes, with internal nodes capable of holding other internal nodes.
Typical leaves are identifier references, integer numbers, etc.
Internal nodes are then unary or binary operations, block containers,
etc.

For optimization purposes, GENERIC is still too high level a
representation.  During a course of compilation, it's lowered.  The
intermediate code that it's lowered into is called \term{GIMPLE}.  The
process of lowering is thus inevitably called \term{gimplification}.
GIMPLE is a subset of GENERIC.  Nesting structures are still
represented as containers in GIMPLE, but all expressions are broken
down to three address code, using temporaries to store intermediate
results\cite{GDS:2003:Merill}.  There are actually two GIMPLE forms: high GIMPLE and low
GIMPLE.  In low GIMPLE containers are further transformed into
\literal{goto}s and labels\cite{LDS:2006:Novillo}.

Apart from pre-defined nodes, GCC provides a mechanism to define your
own GENERIC node types.  Of course it wouldn't know how to gimplify
them, and a langhook is necessary for this purpose.  C and C++
front ends actually don't use GENERIC for their AST representation, but
extend it with their own node types, and then provide means of
gimplification.

\section{Fronted ASTs}

While it is possible to use GENERIC for representation of programs in
your front end, it is recommended not to do so \cite{LDS:2006:Novillo}
\cite{LJ:2005:Tromey}.  Your own AST representation can suit the
language in hand better, and furthermore you are better shielded from
the changes in GCC core.  Besides, the language analysis tools that
you write are then shielded from {\em GCC itself}, which makes them
reusable in other tasks: e.g. as a syntax checker and pretty printer
in smart editors.

This thesis aims very strongly towards the direction of your own AST.
Under such a scenario, there are four layers actually: front end is
further divided into two.  The top one is a generic language
processing library; the bottom one is actual GCC front end, and it
translates one tree form (your AST) into other (GCC's GENERIC).

When you pick the other way, and will represent AST with GENERIC, you
will probably want to read chapters about defining your own GENERIC
codes. \\ \NWY

\section{Source Base}

Unfortunately, all GCC front ends have to be built inside the GCC tree.
There is no way to use e.g. public headers and link against GCC
libraries that would implement lower layers of compilation process.
You will have to store your source files into places where GCC expects
them and adhere to the overall GCC build policy.  In following text,
directories are referred to relatively to the directory where you
unpacked a distribution tar file.  E.g. \file{gcc/} refers to actual
directory \file{gcc-4.2.0/}.

The core of compiler is stored in directory \file{gcc/gcc/}.
Directly in this directory are the files that compose a C Front End,
general GCC services, whole middle end, and a machine independent
parts of back end.  Besides this, there is a number of directories
with front ends.  E.g. \file{gcc/gcc/cp/} contains a C++ front end.
One interesting front end is Treelang (\file{gcc/gcc/treelang/}), a
toy language showing off how to write front ends.  You will have to
create one such directory, chapter \ref{HalloWorld} deals with this.

Another interesting directory is \file{gcc/gcc/testsuite/}, which
contains automated DejaGNU testsuite.  You will most probably want to
have your own files there.  Section \ref{TestSuite}\NWY is dedicated
to subject of writing testsuite.

In toplevel directory, a GCC runtime services are stored.  This
includes runtime libraries for various front ends,
e.g. \file{gcc/libstdc++-v3/} with C++ runtime library.  Most probably
you will want to write your own runtime library.  Section
\ref{RuntimeLibraries} deals with this.

If you can afford depending on GCC, i.e. you don't want your front end
to be completely independent, you can use data types and routines from
a \file{gcc/libiberty/} library.

\section{Garbage Collector}

Internally, GCC uses garbage collector
\footnote{\url{http://gcc.gnu.org/wiki/Memory\_management}}
\cite[chapter Memory Management and Type Information]{TR:GCCInt}
for its memory management.  The objects with indeterminable lifetime,
which includes trees, are not managed explicitely, but instead
garbage-collected.  The collector used is of mark \& sweep kind.
Pointers (variables, fields, ...) that should be collected are
explicitly marked, the marks are gathered during the build, and
marking and scanning routines are generated.

The garbage collector data are also used for implementation of
precompiled headers.  The precompiled header mechanism can only save
static variables if they're scalar. Complex data structures must be
allocated in garbage-collected memory to be saved in a precompiled
header.

\section{Summary}

In this chapter, I covered overall structure of GCC, as well as some
internal details that will be useful later.  Let's recap.

\begin{itemize}

\item The GCC as a whole is composed of a driver and a
  number of actual compilers, one for each language.  Driver knows
  about all the compilers, and depending on its command line settings
  it preprocesses the file, hands it over to one of the compilers, and
  assembles and links its output.

\item The compilers themselves have three layers each: a
  front end, where the language specific logic is located, platform
  independent middle end, and platform dependent back end.

\item The language that is used to represent programs in
  middle end, and that front end emits, is called GENERIC.  GENERIC is
  C-like tree language.  Besides predefined node types, front end
  can register its own node types and use them at will.  Subset of
  GENERIC, used for optimizations, is called GIMPLE, and the process
  of lowering GENERIC to GIMPLE a gimplification.  You have to provide
  gimplifying routines for your front end's own tree nodes.

\item While it is possible to use GENERIC as an AST
  representation, it is advisable to use it rather as a target language,
  and craft the AST to suit your front end's needs.

\item GCC uses garbage collector.  Garbage collected
  structures are marked, and memory scanners are generated based on
  the marks during the build process.

\end{itemize}


% ====================================================================

\chapter[Hello World]{Hello, World!}
\label{HalloWorld}

In this section, we will create minimal GCC front end.  The criteria
are very simple: the front end has to be recognized and compiled by
GCC, and when launched, it has to provide deterministic results; it
must not fail.  Note that we don't require the results to depend in any
way on the source file being compiled.  To cut the teeth, we will
create a front end, whose only purpose is producing the code
equivalent to the following C code:

\program{
\ind\keyw{int} main (\keyw{void}) \{\\
\ind\ind\keyw{return} 7;\\
\ind\}}

The return value of ``7'' is picked arbitrarily.  I used to have ``4''
in its place, but found out that GCC uses 4 as a return value when it
fails, and thus it's less clear when the GCC fails, and when it
succeeds and the binary answers 4.

The prerequisity here is that you already know how to build GCC for
your system.  There is no chance experimenting with front ends if you
never built GCC yourself.  I don't expect you will cross-compile.  See
\ref{CrossCompilationIssues}\NWY if you are interested in that.

Besides reading this chapter, you can find inspiring some other
minimal front ends.  I created a ``Hello World'' front end as part of
work on \literal{gcc-algol}
\footnote{\url{http://projects.almad.net/gcc-algol/browser/trunk/gcc/algol60?rev=58}}.
Surprisingly enough, real ``GCC Hello World''
exists\footnote{\url{http://svn.gna.org/viewcvs/gsc/branches/hello-world/}},
as was brought to my attention later.  Another possibility is to look
at GCC's Treelang front end.

\section{Agenda}

The following will be covered in this chapter:

\begin{enumerate}
\item GCC source base set up; in section \ref{SettingUpSourceBase}.
\item Mandatory files of front end are described.  See
  \ref{uberlang1.c}, \ref{LanguageSpecificComponentsofGCCProper}, and
  \ref{BuildSystemIntegration}.
\item Few tips are given on joining minimal front end with existing
  language parser.  Read \ref{IntegrationofExistingFrontEnd}.
\item Some versioning issues are resolved in \ref{VersioningIssues}.
\end{enumerate}


\section{Setting Up Source Base}
\label{SettingUpSourceBase}

\subsection{GCC Reference Version}

This work is being written with development (as of Dec 2006) version
of GCC in mind.  Given GCC Steering Commitee development
plan\footnote{\url{http://gcc.gnu.org/develop.html}}, this target is
expected to become official GCC-4.3 sometime arount the time
final version of % @@@ remove in final thesis @@@
this work is commited.

\subsection{Create Front End Directory}

Each front end lives in a subdirectory of its own.  Decide on the name
of your fronted and create a subdirectory in \file{gcc/gcc/}.  For
sake of demonstration, I will use the name \literal{uberlang}.

\begin{verbatim}
# cd gcc/gcc/
# mkdir uberlang
\end{verbatim}

Then you will have to populate the front end directory with source
files.  This is covered in sections that follow.

\section{uberlang1.c}
\label{uberlang1.c}

While it is possible to use other languages than C to write GCC front
end, most of GCC is written in C.  There are exceptions, e.g. Java
front end is written in C++, and Ada front end is written in Ada.  I
will give a glimpse of issues that arise from using non-C language, in
section \ref{BootstrappingIssues}\NWY.  For now, I'll assume that you
will start up with simple C source base.

The file \file{uberlang1.c} will make up the compiler itself, or the
front-end-specific part thereof.  It has to contain all the necessary
langhooks, init functions, and data structures that the rest of the
compiler expect from your front end.

\subsection{Custom Data}

Each frontend can have its own data in various GCC data nodes.  Since
there are five kinds of these nodes, five structures will have to be
defined:

\program{
\ind{}// language-specific identifier data\\
\ind{}\keyw{struct} lang\_identifier;\\
\ind{}// language-specific tree node data\\
\ind{}\keyw{union} lang\_tree\_node;\\
\ind{}// language-specific type data\\
\ind{}\keyw{struct} lang\_type\\
\ind{}// language-specific declaration data\\
\ind{}\keyw{struct} lang\_decl\\
\ind{}// language-specific function data\\
\ind{}\keyw{struct} language\_function
}

All structures may be empty, except for the
\variable{lang\_identifier}, which has to contain common part of
identifier definition:

\program{
\ind{}\keyw{struct} lang\_identifier GTY(()) \{\\
\ind{}\ind{}\keyw{struct} tree\_identifier common;\\
\ind{}\};}

This example shows also the \function{GTY(())} mark, necessary for
proper garbage collection scanners to be generated.  Each structure
has to have such a mark.

As the last thing regarding the custom data, you have to provide
definitions of \variable{tree\_code\_type},
\variable{tree\_code\_length}, and \variable{tree\_code\_name} arrays.
These have to contain both the system node types, and your own types.
This is done with the following trick:

\program{
\ind\keyw{\#define} DEFTREECODE(SYM, NAME, TYPE, LENGTH) TYPE,\\
\ind\keyw{const} \keyw{enum} tree\_code\_class tree\_code\_type[] = \{\\
\ind\keyw{\#include} {\it "tree.def"}\\
\ind\ind{}tcc\_exceptional\\
\ind\};\\
\ind\keyw{\#undef} DEFTREECODE\\
}

The file \file{gcc/gcc/tree.def} contains data ready for
preprocessing, with records neatly defined in columns of
\function{DEFTREECODE} calls.  By including this file three times,
each time with different definition of \function{DEFTREECODE}, you
fill the three arrays.

The last member of array is marked with the class
\variable{tcc\_exceptional}, which serves here as a sentinel.  The
name of the last node can be arbitrary, e.g. \literal{\it "@@dummy"},
and the length will be \literal{0}.

\subsection{Langhooks}

The list of all various langhooks is long.  You can find it in file
\file{gcc/gcc/langhooks.h} together with comments.  Default value of
each langhook is in \file{gcc/gcc/langhooks-def.h}.  Both files have
to be \literal{\#included} in \file{uberlang1.c}.  If you are not
comfortable with value (i.e. name) of any given hook, the following
mantra is used to redefine it:

\program{
\ind\keyw{\#undef} LANG\_HOOKS\_INIT\\
\ind\keyw{\#define} LANG\_HOOKS\_INIT uberlang\_init\\
}

Many hooks are predefined in GCC.  The file \file{gcc/gcc/langhooks.c}
contains these definitions.  Any langhooks not defined there have to
be provided by the front end---even if that will be blind definition
from the beginning.  Review of the langhooks that have to be in
minimal frontend, together with the action that has to be taken, is in
table \ref{Table++Langhooks}.  Review of the various actions follow.

\begin{figure}
\begin{tabular*}{15.0cm}{|p{10cm}|p{5cm}|}

\cline{1-2}
Langhook &
Action \\
\cline{1-2}

LANG\_HOOKS\_GLOBAL\_BINDINGS\_P&
\function{gcc\_unreachable}\\

LANG\_HOOKS\_INSERT\_BLOCK&
\function{gcc\_unreachable}\\

LANG\_HOOKS\_PUSHDECL&
\function{gcc\_unreachable}\\

LANG\_HOOKS\_BUILTIN\_FUNCTION&
\function{gcc\_unreachable}\\

LANG\_HOOKS\_TYPE\_FOR\_MODE&
\function{gcc\_unreachable}\\

LANG\_HOOKS\_TYPE\_FOR\_SIZE&
\function{gcc\_unreachable}\\

LANG\_HOOKS\_UNSIGNED\_TYPE&
\function{gcc\_unreachable}\\

LANG\_HOOKS\_SIGNED\_TYPE&
\function{gcc\_unreachable}\\

LANG\_HOOKS\_SIGNED\_OR\_UNSIGNED\_TYPE&
\function{gcc\_unreachable}\\

LANG\_HOOKS\_MARK\_ADDRESSABE&
\function{gcc\_unreachable}\\

\keyw{tree} convert (\keyw{tree} type, \keyw{tree} expr)&
\function{gcc\_unreachable}\\

\cline{1-2}

LANG\_HOOKS\_INIT\_OPTIONS&
empty\\

LANG\_HOOKS\_HANDLE\_OPTION&
empty\\

LANG\_HOOKS\_POST\_OPTIONS&
empty\\

LANG\_HOOKS\_FINISH&
empty\\

\cline{1-2}

LANG\_HOOKS\_INIT&
see \ref{InitializationAndDeinitialization}\\

LANG\_HOOKS\_PARSE\_FILE&
see \ref{ParseFileLanghook}\\

\cline{1-2}

\end{tabular*}

\caption{Breakdown of langhooks in minimal front end.}
\label{Table++Langhooks}
\end{figure}


\subsection{Blinded Out Langhooks}

By blinding langhook out, I have in mind something like this:

\program{
\ind\keyw{void} insert\_block (\keyw{tree} block ATTRIBUTE\_UNUSED) \{\\
\ind\ind{}gcc\_unreachable ();\\
\ind\}}

Function \literal{gcc\_unreachable} aborts the compiler if it is ever
hit by a thread of execution.  If that happens, error message is
printed out denoting the file and line where the offending
\literal{gcc\_unreachable} appeared.

The \literal{ATTRIBUTE\_UNUSED} cookie tells GCC that given variable
may be unused in the function body.  GCC has a very pedantic flag
settings during bootstrapping, and huge amounts of warnings are
printed out for various legal, yet suspicious C constructs.  The
\literal{ATTRIBUTE\_} cookies work as GCC pacifiers, so that you are
actually able to spot any new warnings.

The langhooks that will be blinded out could in fact be empty.  But
having them blinded out will make sure that GCC fails early and
noisily\cite{2003:Raymond} once it tries to use them.  This condition
is easier to track down than when GCC gets nonsensical value in
return, or thinks that langhook did its job, and fails on its own
internal assertion thousands of cycles later.

The function \function{convert} is not a langhook.  It can be blinded
out, too, but it has to be here, and as opposed to langhook functions,
it must not be \literal{\keyw{static}}, because GCC calls is directly.


\subsection{Empty Langhooks}

Some more langhooks need to contain non-failing code, because they are
called always.  They are not required to do anything useful however,
and their bodies may be empty.  This also includes langhooks that
return \literal{NULL\_TREE}, one of the arguments, etc.


\subsection{Initialization And Deinitialization}
\label{InitializationAndDeinitialization}

The setup and teardown are implemented by \function{LANG\_HOOKS\_INIT}
and \function{LANG\_HOOKS\_FINISH} langhooks.  The finish langhook is
among the empty ones, because it doesn't have to contain any code just
now.  It is called after all compilation is done, and you can use it
to clean up whatever is necessary.  Initialization, however, can't be
empty.

Most of GCC is self-initializing, but there are several functions that
need to be called.  Quite possibly your front end requires some
initializations of its own, e.g. to build its own tree nodes for
language standard types.  Init hook is a convenient place to do so.

During initialization you want to call the following functions:

\begin{itemize}
\item \literal{build\_common\_tree\_nodes}, which creates
  nodes for all integer types.

\item \literal{set\_sizetype}, which is used to set the
  type of the internal equivalent of \literal{\keyw{size\_t}}; it is
  simplest to set this always to \literal{long\_unsigned\_type\_node},
  which was created in previous call.

\item \literal{build\_common\_tree\_nodes\_2} uses size
  type to create few more tree types.
\end{itemize}


\subsection{Parse File Langhook}
\label{ParseFileLanghook}

\begin{figure}
\begin{verbatim}
void
algol60_parse_file (int debug ATTRIBUTE_UNUSED)
{
  /* Build declaration of `main' functions */
  tree  main_type =
    build_function_type_list (integer_type_node, NULL_TREE);
  tree  decl = build_function_decl ("main", main_type);
  DECL_CONTEXT (decl) = NULL_TREE;
  TREE_PUBLIC (decl) = 1;
  DECL_ARTIFICIAL (fndecl) = 0;
  DECL_EXTERNAL (decl) = 0;
  TREE_STATIC (decl) = 0;
  DECL_ARGUMENTS (decl) = NULL_TREE;
  rest_of_decl_compilation (decl, 1, 0);

  /* Build RESULT DECLARATION, which is used for storing function
     return value. */
  tree resultdecl
    = build_decl (RESULT_DECL, NULL_TREE, integer_type_node);

  /* Build function BODY:
     `(<block> (return (init_expr resultdecl (int_cst 7))))' */
  tree assign = build2 (INIT_EXPR, void_type_node, resultdecl,
                        build_int_cst (integer_type_node, 7));
  TREE_USED (assign) = 1;
  TREE_SIDE_EFFECTS (assign) = 1;
  tree body = build1 (RETURN_EXPR, void_type_node, assign);
  TREE_USED (body) = 1;
  tree block = build_block (NULL_TREE, NULL_TREE, NULL_TREE, NULL_TREE);
  DECL_SAVED_TREE (decl) = build3 (BIND_EXPR, void_type_node,
                                   NULL_TREE, body, block);
  DECL_INITIAL (decl) = block;
  TREE_USED (block) = 1;

  /* Emit code for the function */
  allocate_struct_function (decl);
  gimplify_function_tree (decl);
  cgraph_finalize_function (decl, false);
  cgraph_finalize_compilation_unit ();
  cgraph_optimize ();
}
\end{verbatim}
\caption{Program listing of parse file langhook}
\label{Figure++ParseFileLanghook}
\end{figure}

This is the langhook that does all the parsing, semantic analysis and
code generation needed for the input file.  This is where our
\literal{\keyw{return} 7;} code resides.

The code itself is listed in figure \ref{Figure++ParseFileLanghook}.
It's quite verbose, and of course by now nothing was written about the
GCC framework, so the functions are not likely to tell you much.  I'll
just cover the basic points, and leave the full elaboration for the
later chapters.

The argument \variable{debug} of the langhook is nonzero, if debugging
messages shoud be dumped to the standard error.  See description of
\option{-dy} in \cite[chapter GCC Command Options]{TR:GCCUser}.

The macros \function{TREE\_PUBLIC}, \function{DECL\_CONTEXT} and
similar are used for runtime access into discriminated union that
makes up node of GENERIC tree.  They set various flags and auxiliary
values of node in question.  In a development tree, there is a runtime
check whether using the macro on a given node is legal.  This check
goes away in final build.  You will want to enable this checking (via
\file{configure} flags) when doing development inside stable GCC tree,
otherwise you will slowly go insane from all the ICEs that will pop
up.

The functions \function{build1}, \function{build2} and
\function{build3} are used to build, respectively, unary, binary, and
ternary GENERIC nodes.  The first argument is the node type, the
second argument is the type of expression, and the remaining arguments
are the children of the node being built.

Meaning of other functions can be more or less deduced from their
name, and the details are not important just now.


\section{Language Specific Components of GCC Proper}
\label{LanguageSpecificComponentsofGCCProper}

\paragraph{The \file{lang-specs.h} file}
describes your front end to the GCC driver.  It tells the driver the
file extensions that, when seen on the command line, should cause GCC
to invoke your front end. It also gives the driver some instructions
for what other programs must be run, such as whether the assembler
should be run after your front end and how to pass or modify certain
command-line options. It may take a while to write this file, as specs
are their own strange language\cite{LJ:2005:Tromey}.

The contents of the file for the minimal front end will be pretty
simple, along these lines:

\program{
\ind\{{\it ".ubl"}, {\it "@ubl"}, 0, 0, 0\},\\
\ind\{{\it ".UBL"}, {\it "@ubl"}, 0, 0, 0\},\\
\ind\{{\it "@ubl"}, \={\it "\%\{!E:uberlang1 \%i \%(cc1\_options) \%\{I*\}"}\\
\ind                \>{\it "\%\{!fsyntax-only:\%(invoke\_as)\}\}"}, 0, 0, 0\},\\
}

This reads, roughly: if no \option{-E} is seen on commandline, invoke
\literal{uberlang1}, which is the name of frontend binary.  Further,
if \option{-fsyntax-only} is not specified, assemble the resulting
file.  Note how the second action is ``embedded'' in the first, thus
providing the context under which it should be considered.

GCC's spec language is described in file \file{gcc/gcc/gcc.c}.

\paragraph{The \file{lang.opt} file}
is an option specification file.  It can be empty for now.  More about
compiler command line options is written in section
\ref{CommandlineOptions}.

\paragraph{The \file{spec.c} file}
contains language-specific GCC driver components.  In particular, two
functions and one variable.  Function
\function{lang\_specific\_driver} is given a vector of commandline
arguments and is free to do any processing, including reordering and
changing the vector, before the main GCC routines take over.  This is
used for linking in language runtime libraries, see
\ref{RuntimeLibraries} for details.

The other function, \function{lang\_specific\_pre\_link}, is called
before linking is done.  Whatever language processing you need can be
done here. The function has to return \literal{0} on success and
\literal{-1} on failure.  We don't need this function, and will leave
it empty.

The variable \variable{lang\_specific\_extra\_outfiles} is used in
concert with \function{lang\_specific\_pre\_link}, and keeps track of
the number of extra output files that
\function{lang\_specific\_pre\_link} may generate.


\section{Build System Integration}
\label{BuildSystemIntegration}

\paragraph{The \file{config-lang.in} file}
is a sort of high-level descriptor of your frontend.  It contains
variables for toplevel \file{configure} (i.e. it's written in a shell
syntax).  The file is very simple overall and only defines few
variables:

\program{
language={\it{}"uberlang"}\\
compilers={\it{}"uberlang1\$(exeext)"}\\
gtfiles={\it{}"\$(srcdir)/uberlang/uberlang1.c"}\\
}

The variable \variable{language} defines the name of the front end as
recognized by the build system.  This is really a name of the
language, it doesn't have to match name of the front end subdirectory.
Users will call this your language on \file{configure} command line
when they'll wish to include it in GCC build.

Variable \variable{compilers} contains list of all compilers created
during the build.

Very important variable \variable{gtfiles} contains the list of files
that should be scanned for \function{GTY(())} marks.  Garbage
collection scanners are built from these.

More is written about this file, and which variables are recognized,
in \cite[section Anatomy of a Language Front End]{TR:GCCInt}.

\paragraph{The \file{Make-lang.in} file}
serves as a fragment of \file{Makefile.in}, from which
\file{configure} will eventually create \file{Makefile}.  GCC build
machinery does calls into front end-specific \file{Makefile}, and you
have to implement certain targets.

@@@ has to be written.



\section{Integration of Existing Parser}
\label{IntegrationofExistingFrontEnd}

Chances are you already have the language processor written, and need
to integrate it into the GCC.  (By the way, this is the approach that
I have taken.  Parts of \Algol compiler were written long before I
started poking GCC.)

\subsection{Joining In The Minimal Front End}

At this point, you have two components in hand: a minimal GCC front
end, and your compiler.  The first step should be inclusion into the
build system.  If you don't want to port entire compiler over to GCC's
\file{Makefile} machinery, you will have to invent some mechanism of
transferring the build into your subdirectory.  Basically
\literal{\$(MAKE) -C} should be enough, but you will have to take care
of passing necessary build/host/target trichotomy
\footnote{See section \ref{CrossCompilationIssues} for details.}
variables and paths over to your build system, and respecting them
there.  This in fact holds for all various variables that are passed
from one recursive make instance to the other.

You may want to take advantage of certain GCC's services.  E.g. error
reporting, integrated testsuite, building runtime library as part of
overall build; or you may with to extend your language with various
GCC-isms
\footnote{Yes, I know this term is pejorative.  But this doesn't
decrease usefullness of certain GCC-specific constructs.}, such as
C-like preprocessing or inline assembly.  These themes are covered in
dedicated chapters \ref{GCCServices} and \ref{LanguageExtenstions},
respectively. \NWY

For special-casing the code that's built as part of GCC, you can use
\variable{IN\_GCC} preprocessor variable.  It's \literal{\#defined}
when the file is built as part of GCC build process.

It's not usually a good idea to mess GCC and an existing code.  GCC's
garbage collecting engine has infamous habit of poisoning certain
memory-related functions (e.g. \function{malloc}, \function{calloc},
\function{strdup}).  Using these symbols then leads to code that is
classified by cpp:

\program{cpp error: attempt to use poisoned malloc}

Hand-managed code is OK with GCC, so it's best to keep the collector
off already written codebase.

\subsection{Versioning Issues}
\label{VersioningIssues}

Most probably, you will want to keep your frontend versioned
separately from the GCC itself.  I will describe the approach that I'm
taking.  Toplevel \file{trunk/} directory (I'm using subversion, but
of course, you are free to keep your stuff versioned to your likings)
contains the following subdirectories:

\begin{verbatim}
trunk/doc/
trunk/gcc/
trunk/gcc/libga60/
trunk/gcc/gcc/
trunk/gcc/gcc/algol60/
trunk/gcc/gcc/testsuite/
trunk/gcc/gcc/testsuite/lib/
trunk/gcc/gcc/testsuite/algol60.dg/
\end{verbatim}

More will be written about the \file{trunk/gcc/libga60/} and
\file{trunk/gcc/gcc/testsuite/} in their respective sections,
\ref{RuntimeLibraries} and \ref{TestSuite}. For now, you can skip
their description, if you so wish. \NWY

The toplevel split to \file{trunk/doc/} and \file{trunk/gcc/} is here
to keep my diploma thesis texts separated from the GCC development
part.  This may come in handy in your case, too, if you want to keep
the GCC subtree clean, and store e.g. documentation, scripts, etc.
separately.

The subtree rooted at \file{trunk/gcc/} mimics GCC's distribution
subtree (e.g. \file{gcc-4.2.0/}).  This is advantageous for two
reasons.  First, you can just tar and zip the gcc subdirectory (no
including toplevel \file{gcc/} itself, i.e. after unpacking, the two
directories \file{gcc/} and \file{libga60/} will appear), and
distribution package is ready.  User will just enter the GCC's
distribution directory, upack your front end here, do necessary
patching, and GCC tree is ready to build your front end.  Second, it
keeps the things tidy.

Then I just symlink the files from GCC
tree into my front end tree.  This is only possible on systems that
support symlinks, but with GCC being unixy compiler, it is reasonable
requirement.  In several cases, symlinking works as intended even on
directory level:

\begin{verbatim}
gcc/gcc/algol60
  -> ../gcc-algol/trunk/gcc/gcc/algol60
gcc/gcc/testsuite/algol60.dg
  -> ../gcc-algol/trunk/gcc/gcc/testsuite/algol60.dg
\end{verbatim}

But for test suite, you will have to add two files into subdirectory
\file{gcc/gcc/testsuite/lib/}, and you have to symlink those two files
explicitly:

\begin{verbatim}
gcc/gcc/testsuite/lib/algol60-dg.exp
  -> ../gcc-algol/trunk/gcc/gcc/testsuite/lib/algol60-dg.exp
gcc/gcc/testsuite/lib/algol60.exp
  -> ../gcc-algol/trunk/gcc/gcc/testsuite/lib/algol60.exp
\end{verbatim}

The directory that really causes trouble is \file{gcc/libga60/}, a
runtime library subdirectory.  Build scripts will use the path in
a relative manner: \file{gcc/libga60/../}.  This doesn't work with
symlinks, because the \file{../} component will point to the target
directory's \file{../}, not back to \file{gcc/}.  For
this reason I had to create \file{gcc/libga60/} as an ordinary
directory, and symlink there all the files from front end's
\file{gcc/libga60/}.  You will have to either take care and symlink
back by hand when someone adds new files into version system, or store
all source files in subdirectory e.g. \file{gcc/libga60/src/}, symlink
that, and only keep in \file{gcc/libga60/} the build machinery files
that need to be there.

\section{Summary}

\begin{itemize}

\item Each frontend lives in a directory of its own.  Even for minimal
  frontend, several files are necessary to honor requirements of GCC
  build system.  They are \file{lang-specs.h} with the description of
  actions that should be taken depending on the source file suffix and
  command line switches; \file{lang.opt} with the description of
  command line switches specific to your frontend (this file may be
  empty); \file{config-lang.in} with meta-data about your frontend;
  \file{Make-lang.in} with the description of build itself;
  \file{spec.c} with language-specific components of GCC compilation
  process; and \file{{\it your-language-name}1.c} with the code
  itself.

\item The file \file{{\it your-language-name}1.c}, in the past chapter
  conveniently called \file{uberlang1.c}, contains the GCC that is
  required by the rest of GCC stack.  This includes definitions of
  custom data structures and language hooks.  Most language hooks,
  though required to be defined, may be empty of blinded out.  Some of
  them must contain a code, most prominently \function{INIT} and
  \function{PARSE} langhooks.

\item To keep GCC garbage collector happy, you will have to annotate
  data structures with \literal{GTY(())} tags.  Furthermore, all files
  that contain such annotations have to be included in a list
  \variable{gtfiles} in \file{config-lang.in}.

\end{itemize}


%=====================================================================%

\chapter{Targeting GCC}
\label{TargetingGCC}

This chapter should describe how to generate GCC intermediate language
called GENERIC.  Also use hooks if possible.

\section{Symbol Handling}

Symbol handling: probably has to be front end specific, although GCC
can store declarations.  See how other frontends do their thing.  Name
mangling, C and C++-compatible interfacing (extern "C").

\section{Variables and Types}

How to do typechecking, representing various types (including arrays,
functions, structures).  About variables: function-static, automatic,
file-static and global.  Notes on initialization of misc variable
kinds/types (e.g. how does initialization of file-static struct differ
from initialization of automatic array).

Arrays: variable sized arrays, multidimensional arrays.

\section{Expressions}

Variable reference, constants, various expression kinds.

\section{Structured Programming}

Nested blocks; for, while, do; if, switch; goto and labels.

\section{Functions}

Declarations/definitions, function calls, global, local (nested),
file-static, overloaded, builtin, anonymous. Pass by value, reference
and name, varargs.
Builtins.

Interprocedural optimizations \cite{GDS:2004:Hubicka}, intermodule
optimizations \cite{GDS:2005:Keating}.

\section{Modules}

Variable/function visibility, module ctors and dtors.  Namespaces.

\section{Object-oriented programming}

Objects, dynamic typing (look at OBJ\_TYPE\_REF), virtual functions.

\section{Numbers}

Elaborate on numeric support in GCC.  Including big integers, long
floats, what's necessary big/little endian-wise, if there's anything
to know about bits-per-byte, complex numbers (and what are possible
types of complex number components).  Floating point, integer and
string literals.

Look into \cite{GDS:2005:Grimm}, \cite{GDS:2006:Sidwell}.

Read this:
\url{http://gcc.gnu.org/ml/gcc-patches/2003-09/msg00862.html}
and this:
\url{http://gcc.gnu.org/bugzilla/show\_bug.cgi?id=29335}.
Seems that inclusion of GMP in GCC means we can use the same functions
both for constant folding and for runtime computations.
Using gmp/mfpr in runtime vs. using systemwide libm.

\begin{quote}
I think using long double defeats the whole purpose of using mpfr.  We're
supposed to avoid relying on the properties of the host's floating point for
cross-compilers where the target format is different.  Otherwise I could simply
call out to e.g. cosl() on the host and avoid the whole mpfr thing (okay okay,
assuming cosl() and the rest of c99 math functions exist... which they don't
always, but my point about target long double remains.)
\end{quote}

\begin{quote}
I think there's a very important distinction that needs to be drawn
between a tool that needs to be installed to *build* gcc and a tool that
needs to be installed in order to *run* gcc.  GMP/MPFR is needed for the
latter;
\end{quote}
(Aha, so gmp stuff is really meant to be used in constant folding.)

\section{Extending GENERIC}

What are custom GENERIC codes, how to declare them, how to handle
them, what's gimplification, how to gimplify them.

Look into \cite{GDS:2005:Dvorak}.  Maybe find better source.

%=====================================================================%

\chapter{GCC Services}
\label{GCCServices}

\section{Commandline Options}
\label{CommandlineOptions}

Each GCC compiler has the capability of processing commandline
options.  Moreover it inherits all the options
from the main part of GCC, so
e.g. \option{-O3}, \option{-o file} and others are available for all
frontends with no work.  The only work is necessary for definition of
options peculiar to given frontend, and even there is the tedium of
commandline parsing left off your shoulders.

\subsection{Processing Options}

GCC understands both positive and negative variants of \option{-f} and
\option{-W} options.  E.g. when your frontend supports
\option{-fdump-ast}, GCC will understand also \option{-fno-dump-ast}.
Furthermore, each option can be parametrized.  Thus you can have
e.g. \option{-{}-output-pch=} option for output of precompiled headers,
and the part after ``='' is delivered to option handler as an
argument.

Of course, you have to write the handler for frontend-specific
options yourself.  All the work takes place in
\function{LANG\_HOOKS\_HANDLE\_OPTION} hook, GCC calls this function
each time it hits an option that the frontend understands.  The
communication isn't done through option strings, though.  Instead, GCC
associates each option a symbolic identifier with unique integer
value.  When option is handled, simple \literal{switch} statement can
be used to decide what should be done.  Option strings are transformed
to identifiers in a straightforward manner: each non-alphanumeric
character in a string is replaced with underscore, and \literal{OPT}
is prepended before the resulting string.  Thus
e.g. \option{-{}-output-pch=} is referred-to by identifier
\variable{OPT\_\_output\_pch\_}.

Other parameters in option-handling hook are \variable{argument} and
\variable{value}.  Variable \variable{argument} is either
\variable{NULL}, or it holds a string with the extra option argument
(as was described few paragraphs up).  The variable \variable{value}
is 1 if an option is used in its positive variant, and 0 for
\option{no-} variant.

Option handling hook can return three values: \literal{0} if the
option was invalid, \literal{1} is if was valid, and \literal{-1} if
it was valid and no further processing of the option should be done.

\subsection{Defining New Options}

All front-end-specific options are defined in \file{lang.opt}.  This
file gives, through build magic, rise to \file{options.h}.  Format and
features of \file{lang.opt} are to be found in GCC internals
documentation
\cite[chapter Options]{TR:GCCInt}.

A warning is due when changing the \file{lang.opt} file.  Almost whole
GCC depends on \file{options.h}, directly or indirectly.  Changing
\file{lang.opt} will lead to almost whole bootstrap being processed
again.  Have a cup of tea ready before doing so.

\subsection{Interesting Langhooks}

Following langhooks are of interest when you are doing option
processing:

\begin{enumerate}

\item \function{LANG\_HOOKS\_INIT\_OPTIONS} is called before any
  option processing is done.  You will probably want to initialize
  your flags to their default values here.

\item \function{LANG\_HOOKS\_HANDLE\_OPTION} is called to handle a
  single command-line option.

\item \function{LANG\_HOOKS\_MISSING\_ARGUMENT} is called when the
  argument is missing to the option that requires one.  The hook is
  handed over an offending argument string and its unique identifier.
  If it answers \literal{false}, default missing-argument complaint
  should be used.  \literal{true} means that you took care of the
  error message yourself.

\item \function{LANG\_HOOKS\_POST\_OPTIONS} is called after all
  command-line processing has been done.  This lang hook also is a
  convenient place to determine the name of the input file to parse.
\end{enumerate}

\section{Diagnostics}

Employing GCC diagnostic messages.  Btw, you really want to do that,
otherwise your buggy programs will be passed and a binary generated,
or GCC crashed, depending on how is your error handling done.
Describe the `pedantic' variable.  Describe pedwarn, warning, error
and friends.  report\_diagnostic, diagnostic\_info and friends.
Report code excerpts with verbatim.  It seems that GCC uses it's own
printing functions, with their own formatting.  See e.g. comment
before pp\_base\_format.  Describe that.

See this:
\url{http://vmlinux.org/joachim/mirror/www.objsw.com/CrossGCC/FAQ-12.html}.

\section{Runtime Libraries}
\label{RuntimeLibraries}

Languages usually need a support beyond mere syntactic and semantic
actions.  This includes input and output routines, some cunning
numerical algorithms for scientific languages, or simply language
standard library, such as \literal{libstdc++} or \literal{java}
platform.  Most probably you will have to roll one of these for your
language.

Runtime support also includes system's \literal{libc} and
\literal{libm}.  To honor GCC interfaces, you will have to pay some
attention to these, too.

GCC doesn't support integration of the runtime library with the same
ease it supports new language frontends.  There are files to be
patched, an operation inherently unsafe in a volatile environment of
GCC trunk.  Apart from that, however, the automation works nicely,
and with some rules in mind, you can build cross-compilation safe
runtime library that is linked to your binaries by default.  Let's get
dirty!

\subsection{Agenda}

You need the following.

\begin{enumerate}
\item To write the library itself.  This includes source files and
  build system.
\item To include the library into the build chain.  This includes
  patching toplevel \file{configure} and \file{Makefile.def}.
\item To inject the library into compilation commandline, so that it's
  linked in produced binaries.
\end{enumerate}

\subsection{The Library Subdirectory}

Given a toplevel directory \file{gcc}, runtime libraries typically
reside in subdirectory \file{gcc/libsomething}.  This directory is
basically ordinary library build directory: it is almost possible to
simply copy preexisting library files there.

GCC expects that the library provides a \file{configure} script,
which, when launched, creates \file{Makefile}.  (Note that the created
\file{Makefile} has to reside in a {\em build} directory, but the
script is launched from a {\em source} directory.)  I assume that you
obey autotools, as it will save you a lot of work.

The best approach is probably simply to take other frontend's
\file{configure.ac} and \file{Makefile.am}, look how is it done, and
bend it to suit your needs.  The files are mostly classical autotools
source files, but there are certain hacks here and there necessary for
integration into GCC build system.  In particular:

\begin{itemize}
\item \file{configure.ac} has to call \variable{GCC\_TOPLEV\_SUBDIRS}
  macro after \variable{AC\_INIT}.  This relates to the dreaded
  GCC{}'s build/host/target trichotomy.  Each of builds is separated
  in directory of its own: \variable{build\_subdir},
  \variable{host\_subdir}, and \variable{target\_subdir}.  This macro
  determines these values.

\item In \file{Makefile.am}, \variable{gcc\_version} has to be
  calculated for use in expansion of \variable{toolexeclibdir}
  variable.  This can be done by reading the contents of file
  \file{gcc/gcc/BASE-VER}.

\item libtool version info (i.e. library soname) is not hardcoded into
  the \file{Makefile}, but rather is stored in a file called
  \file{gcc/libsomething/libtool-version}.  This is not compulsory
  step, it just eases things a bit in that you don't have to rebuild
  autotools-generated files when you update library version.
\end{itemize}

Besides the concrete cases just mentioned, other frontends usually
contain workarounds that were necessary to resolve problems in past.
It's certainly not wise to copy blindly every hack, as many of them
may be outdated and superfluous.  But other implementors likely fallen
into the same traps you did, and reinventing the wheel rarely pays
off.

\subsection{Patching Toplevel Buildsystem}

One last step is necessary before your library gets built as part of
build process.  GCC has to {\em know} about it.  As it is, you have
to touch GCC{}'s privates to do it: you need to patch toplevel
\file{configure} and \file{Makefile.def}.  Fortunately, both patches
are trivial.

There is a variable \variable{target\_libraries} in toplevel
\file{configure}.  As the name implies, what libraries get built is
driven by the contents of this variable.  You need to add the name of
your library among the others.

Patching \file{Makefile.def} is more creative task.  This file is used
in concert with \file{Makefile.tpl} by a tool called \literal{autogen}
to produce \file{Makefile.in}.  Inside \file{Makefile.def}, it is
possible to express various inter-library dependencies to define exact
conditions when your library should be built, as well as whether the
library should be installed, bootstrapped, or checked.

@@@TODO if there is time, revisit this section and write some more
about what and how can be defined.@@@

\subsection{Linking the Binaries With Runtime Library}

The method that GCC uses to decide which runtime libraries to link in
is pretty much a hack: you will inject necessary libraries into the
commandline, before it's processed.

The work is done in \function{lang\_specific\_driver}.  Very general
commandline tweaking can take place here.  The function is given
pointer to \variable{argc} and \variable{argv} variables, and is free
to reorder, add or remove any of the arguments as seems fit.  To
support proper linking, you will want to detect the situation when
your runtime library, \literal{libc}, \literal{libm}, or any other
required library isn't at the commandline yet (or is and shouldn't
be), in which situation you will add or remove it from the vector and
adjust \variable{argc} accordingly.  It's necessary to support native
GCC switches, such as \option{-nostdlib} and \option{-nodefaultlibs},
as well as your own switches that imply that no linking is to be done
(e.g. \option{-fsyntax-only} or similar).

Unfortunately that implies processing commandline arguments one at a
time, skipping their arguments as necessary (think \option{-o},
\option{-Xlinker}).  It's really not nice solution, but that's the way
it works.

\subsection{Depending on System Libraries}

You may or may not want to depend on system libraries, such as
\literal{libc} or \literal{libm}.  Their handling is mostly the same as
handling your own runtime library, except that you don't have to build
them.

@TODO:maybe move to numerical support chapter:
Since version 4.3.0, GCC uses \literal{libgmp} to do its constant
folding, which means that the library will be available at compiler
runtime.  Very often that means the library will also be available at
binary run site.  That doesn't hold universally, but at least
\literal{libgmp} was ported to all platforms where GCC has supported
backends.  What this means for you is that you can dispatch to this
library many numerical algorithms that would otherwise have to be
handrolled or cut'n'pasted.  As far as I know, this is the approach
Fortran fronted is about to take.


\section{Testsuite}
\label{TestSuite}

What's dejagnu testsuite, how to write tests, how to integrate them
into GCC testsuite.  You need acurate error reporting to use the
dejagnu GCC framework.  In fortran, they are doing transformations of
error messages to format expected by the framework, describe that.

\section{Debuginfo}

How to add debuginfos to binaries that your frontend produces.  How to
use gdb for your language.

%=====================================================================%

\chapter{GCC-Specific Language Extensions}
\label{LanguageExtenstions}

This chapter describes various extensions that you might want to
include to your language.  Not really GCC-only, but GCC supports them.

\section{Attributes}

Employing attributes.  How does frontend handle attributes, how does
it define its own.

\section{Preprocessing}

Employing libcpp.  How to use preprocessor for your language.

\section{Inline Assembly}

Employing assembly.  How to add GCC-compatible inline assembly into
your language.

\section{Open MP}

If the time permits, elaborate on how to use Open MP in frontend.
Look into \cite{GDS:2006:Novillo}.

%=====================================================================%


\chapter{Advanced Topics}

\section{Cross-compilation Issues}
\label{CrossCompilationIssues}

Elaborate on build-host-target trichotomy.  Assure ga60 is
cross-compilation capable and describe what problems there were.

\section{Bootstrapping Issues}
\label{BootstrappingIssues}

How to write a library and/or frontend in a language whose compiler is
built as part of gcc, but not in the language itself.  How to write a
library and/or frontend in a language itself.

%=====================================================================%


\chapter{Conclusions}

Conclusions: ``short, concise statements of the inferences that you
have made because of your work. It helps to organize these as short
numbered paragraphs, ordered from most to least important.''

Summary of Contributions: ``The Summary of Contributions will be much
sought and carefully read by the examiners.  Here you list the
contributions of new knowledge that your thesis makes. Of course, the
thesis itself must substantiate any claims made here. There is often
some overlap with the Conclusions, but that's okay. Concise numbered
paragraphs are again best. Organize from most to least important.''

Future Research: How feasible would be to have a frontend, that just
hands all the calls to dynamically loaded external parser?  This would
allow for out-of-tree builds, wouldn't it?

\bibliographystyle{plain}
\bibliography{dp}

\chapter*{Appendix: Frontend-to-Middleend Interface}

Describe all data structures that frontend touches.
http://gcc.gnu.org/projects/documentation.html, project "Fully
document the interface of front ends to GCC"

\chapter*{Appendix: \Algol 60 Compiler}

Installation, supported GCCs, usual stuff.



\chapter{Notes}

Functions need a return statements.  Look how it's done for noreturn
functions.

COND\_EXPR breaks when other value than 0 or 1 is used as condition.


\end{document}

% Local Variables:
% compile-command: "make show-dp"
% End:
