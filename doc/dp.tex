\documentclass[czech]{fitprj}
%\documentclass[a4paper,11pt]{report}
%\usepackage{a4wide}
\usepackage[latin2]{inputenc}
\usepackage[
  bookmarks=true,
  bookmarksopen=true,
  bookmarksopenlevel=2,
  pdfhighlight=/I,
  pdftitle=Construction\ of\ GNU\ Compiler\ Collection\ Frontend,
  pdfauthor=Petr\ Machata,
  pdfstartview=FitH,
  pdfborder={0 0 0}
  ]{hyperref}
\usepackage{subscript}
\pagestyle{empty}
\topmargin 0in

\date{29. Øíjna}
\setyear{2006}
\author{Bc. Petr Machata}
\title{Construction of GNU Compiler Collection Frontend}
\FITproject{DP}

\edeclaration{
    Prohla¹uji, ¾e jsem tuto diplomovou práci vypracoval samostatnì pod
    vedením Ing. Milo¹e Eysselta, CSc.
    Dal¹í informace mi poskytl zamìstnanec firmy ANF Data, Ing. Luká¹ Szemla
    % ujistit se ze je to tak spravne, jestli neni nahodou taky vedouci
    Uvedl jsem v¹echny literární prameny a publikace, ze kterých jsem èerpal.
    }

\acknowledgements{
Thanks to... (FIT BUT that they gave up their rights)
}


\fitabstract{The Abstract}

\keywords{GCC, GNU Compiler Collection, frontend, front end, Algol 60, compiler}

\fitabstractCZ{Abstrakt}

\keywordsCZ{GCC, GNU Compiler Collection, pøední èást, Algol 60, kompilátor}

\begin{document}

\maketitle
% tady bude zadani
\grantrights
\abstractkeywords
\abstractkeywordsCZ
\FITstart

\def\Algol{{\sc Algol}\space}
\def\GCC{{\sc GCC}\space}
\def\C{{\sc C}\space}

% for various computer-related terms
\def\literal#1{{\sffamily{}#1}}
% functions names
\def\function#1{{\sffamily{}#1}}
% file names
\def\file#1{{\sffamily{}#1}}
% commandline options
\def\option#1{{\sffamily{}#1}}
% variables, types, and similar
\def\variable#1{{\sffamily{}#1}}

% program listings
\def\program#1{{\sffamily\begin{tabbing}#1\end{tabbing}}}
% keywords in program listings
\def\keyw#1{{\sffamily\bfseries {#1}}}
% indentation
\def\ind{\hspace{0.5cm}}

\def\note#1{{{\it Note.\space}#1}}
\def\output#1{{\ttfamily\begin{tabbing}#1\end{tabbing}}}

% ====================================================================

\tableofcontents

% ====================================================================

\chapter{Introduction}

Describe what this thesis is about, summarize chapters, provide
insight to how to read it.

\chapter{Why GCC, Why Now}

(Reference: Tom Tromey's Java paper) Summarize options available when
one writes new language.  Interpreters and compilers, hand-rolling
compiler, compiling via C (this sucks mostly because C compiler has to
recover the higher level model from C, which of course isn't possible;
and debugging--GCC will preserve symbol names where necessary, while
in C, you'd have to mangle them without chance to give a clue to
target C compiler (you want to emit \#line directives to point the user
to the place where the error originated, and in debugger you have no
way to hide the fact that you are going through C)), compiling via GCC
(what if it's dynamic language, what if static).

Personal opinions aside, writing GCC frontend is probably best choice.
GCC is ported to dozens of platforms, has tons of optimizations, has
necessary community, corporation and academia drive, and finally
writing such frontend isn't nearly as difficult as rolling your own
backend (fingers crossed it's true).
Even rolling C backend would be a pain for some language features,
such as exception handling and object orientation, that GCC readily
supports.

Describe briefly that the author has written \Algol 60 parser
\cite{TR:ALGOL60}
to get
himself familiar with the stuff he describes.  Maybe drop a few notes
about how the parser (independent from GCC) and GCC frontend got
joined.

\chapter{GCC Architecture}

How does GCC work.  What's driver, what's the frontend proper.  Bird's
eye view of compilation passes, internal structure, references to
other documents with more detailed description.  Main source will be
Diego Novillo's OLS paper.  Mention garbage collector (only mention).
Also
mention hooks, but don't go into depth (go as far as Tom Tromey's
Linux Journal article).

Mention that there are two approaches: targeting GENERIC, and using
GENERIC as AST rep.  This work aims at the former scenario.  Under
this setup, there are four levels actually: your parser, GCC frontend,
GCC middleend, GCC backend.  The frontend of the parser is completely
independent of GCC, backend of the parser is frontend of the GCC.
With the latter approach, one defines special tree codes.

Build on \cite{GDS:2003:Merill}, \cite{LDS:2006:Novillo},
\cite{GDS:2006:Mulley}, \cite{LJ:2005:Tromey}.

\chapter[Hello World]{Hello, World!}

What's Make-lang.in, config-lang.in, lang-specs.h, algol60.texi.

Compilation process: why language subdirectory, what happens with
Make-lang.in and config-lang.in, what's bootstrapping.  Defining
hooks, defining options.
Note: recompilation after the change of lang.opt takes forever.
Note 2: correction: it takes *aeons*.
On my box:
real	162m16.769s
user	116m27.430s
sys	2m49.900s
i.e. almost three hours





\section{Other section}

This work includes frontend template.  That's the smallest possible
frontend, that even doesn't emit any code, just writes out some stuff
(but it has all inits in place and ready for real thing).  Go through
the files and code in that template, and briefly describe hooks and
interesting things.  Leave the full catalogues to subsequent chapters.

About integration.  Mention slow round trip time: edit->compile->test
loop tends to be quite lengthy with GCC; you really want fast machine.
You can use IN\_GCC to special case your frontend to use GCC services
where available.

GCC uses garbage collector.  Describe GCC poisoning.  Probably go
through some GC codes, if apropriate.

%=====================================================================%

\chapter{Targeting GCC}

This chapter should describe how to generate GCC intermediate language
called GENERIC.  Also use hooks if possible.

\section{Symbol Handling}

Symbol handling: probably has to be frontend specific, although GCC
can store declarations.  See how other frontends do their thing.  Name
mangling, C and C++-compatible interfacing (extern "C").

\section{Variables and Types}

How to do typechecking, representing various types (including arrays,
functions, structures).  About variables: function-static, automatic,
file-static and global.  Notes on initialization of misc variable
kinds/types (e.g. how does initialization of file-static struct differ
from initialization of automatic array).

Arrays: variable sized arrays, multidimensional arrays.

\section{Expressions}

Variable reference, constants, various expression kinds.

\section{Structured Programming}

Nested blocks; for, while, do; if, switch; goto and labels.

\section{Functions}

Declarations/definitions, function calls, global, local (nested),
file-static, overloaded, builtin, anonymous. Pass by value, reference
and name, varargs.

Interprocedural optimizations \cite{GDS:2004:Hubicka}, intermodule
optimizations \cite{GDS:2005:Keating}.

\section{Modules}

Variable/function visibility, module ctors and dtors.  Namespaces.

\section{Object-oriented programming}

Objects, dynamic typing (look at OBJ\_TYPE\_REF), virtual functions.

\section{Numbers}

Elaborate on numeric support in \GCC.  Including big integers, long
floats, what's necessary big/little endian-wise, if there's anything
to know about bits-per-byte, complex numbers (and what are possible
types of complex number components).  Floating point, integer and
string literals.

Look into \cite{GDS:2005:Grimm}, \cite{GDS:2006:Sidwell}.

\section{Extending GENERIC}

What are custom GENERIC codes, how to declare them, how to handle
them, what's gimplification, how to gimplify them.

Look into \cite{GDS:2005:Dvorak}.  Maybe find better source.

%=====================================================================%

\chapter{GCC Services}

\section{Commandline options}

Each \GCC frontend has the capability of processing commandline
options.  Moreover it inherits all the options from \GCC proper, so
e.g. \option{-O3}, \option{-o file} and others are available for all
frontends with no work.  The only work is necessary for definition of
options peculiar to given frontend, and even there is the tedium of
commandline parsing left off programmer's shoulders.

\GCC understands both positive and negative variants of \option{-f},
\option{-W} and \option{-m} options.  E.g. when your frontend supports
\option{-fdump-ast}, \GCC will understand also \option{-fno-dump-ast}.
Furthermore, each option can be parametrized.  Thus you can have
e.g. \option{-{}-output-pch=} option for output of precompiled headers,
and the part after ``='' is delivered to option handler as an
argument.

Of course, programmer has to write the handler for frontend-specific
options herself.  All work takes place in
\function{LANG\_HOOKS\_HANDLE\_OPTION} hook, \GCC calls this function
each time it hits an option that the frontend understands.  The
communication isn't done through option strings, though.  Instead, \GCC
associates each option a symbolic identifier with unique integer
value.  When option is handled, simple \literal{switch} statement can
be used to decide what should be done.  Option strings are transformed
to identifiers in a straightforward manner: each non-alphanumeric
character in a string is replaced with underscore, and \literal{OPT}
is prepended before the resulting string.  Thus
e.g. \option{-{}-output-pch=} is referred-to by identifier
\variable{OPT\_\_output\_pch\_}.

Other parameters in option-handling hook are \variable{argument} and
\variable{value}.  Variable \variable{argument} is either
\variable{NULL}, or it holds a string with the extra option argument
(as was described few paragraphs up).  The variable \variable{value}
is 1 if an option is used in its positive variant, and 0 for
\option{no-} variant.

All frontend-specific options are defined in \file{lang.opt}.  This
file gives, through build magic, rise to \file{options.h}.  Format and
features of \file{lang.opt} are to be found in \GCC internals
documentation
\cite[chapter Options]{TR:GCCInt}.

\section{Diagnostics}

Employing GCC diagnostic messages.  Btw, you really want to do that,
otherwise your buggy programs will be passed and a binary generated,
or GCC crashed, depending on how is your error handling done.
Describe the `pedantic' variable.  Describe pedwarn, warning, error
and friends.  report\_diagnostic, diagnostic\_info and friends.
Report code excerpts with verbatim.  It seems that GCC uses it's own
printing functions, with their own formatting.  See e.g. comment
before pp\_base\_format.  Describe that.

\section{Runtime Libraries}

Languages usually need a support beyond mere syntactic and semantic
actions.  This includes input and output routines, some cunning
numerical algorithms for scientific languages, or simply language
standard library, such as \literal{libstdc++} or \literal{java}
platform.  Most probably you will have to roll one of these for your
language.

Runtime support also includes system's \literal{libc} and
\literal{libm}.  To honor \GCC interfaces, you will have to pay some
attention to these, too.

\GCC doesn't support integration of the runtime library with the same
ease it supports new language frontends.  There are files to be
patched, an operation inherently unsafe in a volatile environment of
\GCC trunk.  Apart from that, however, the automation works nicely,
and with some rules in mind, you can build cross-compilation safe
runtime library that is linked to your binaries by default.  Let's get
dirty!

\subsection{Agenda}

You need the following.

\begin{enumerate}
\item To write the library itself.  This includes source files and
  build system.
\item To include the library into the build chain.  This includes
  patching toplevel \file{configure} and \file{Makefile.def}.
\item To inject the library into compilation commandline, so that it's
  linked in produced binaries.
\end{enumerate}

\subsection{The Library Subdirectory}

Given a toplevel directory \file{gcc}, runtime libraries typically
reside in subdirectory \file{gcc/libsomething}.  This directory is
basically ordinary library build directory: it is almost possible to
simply copy preexisting library files there.

\GCC expects that the library provides a \file{configure} script,
which, when launched, creates \file{Makefile}.  (Note that the created
\file{Makefile} has to reside in a {\em build} directory, but the
script is launched from a {\em source} directory.)  I assume that you
obey autotools, as it will save you a lot of work.

The best approach is probably simply to take other frontend's
\file{configure.ac} and \file{Makefile.am}, look how is it done, and
bend it to suit your needs.  The files are mostly classical autotools
source files, but there are certain hacks here and there necessary for
integration into \GCC build system.  In particular:

\begin{itemize}
\item \file{configure.ac} has to call \variable{GCC\_TOPLEV\_SUBDIRS}
  macro after \variable{AC\_INIT}.  This relates to the dreaded
  \GCC{}'s build/host/target trichotomy.  Each of builds is separated
  in directory of its own: \variable{build\_subdir},
  \variable{host\_subdir}, and \variable{target\_subdir}.  This macro
  determines these values.

\item In \file{Makefile.am}, \variable{gcc\_version} has to be
  calculated for use in expansion of \variable{toolexeclibdir}
  variable.  This can be done by reading the contents of file
  \file{gcc/gcc/BASE-VER}.

\item libtool version info (i.e. library soname) is not hardcoded into
  the \file{Makefile}, but rather is stored in a file called
  \file{gcc/libsomething/libtool-version}.  This is not compulsory
  step, it just eases things a bit in that you don't have to rebuild
  autotools-generated files when you update library version.
\end{itemize}

Besides the concrete cases just mentioned, other frontends usually
contain workarounds that were necessary to resolve problems in past.
It's certainly not wise to copy blindly every hack, as many of them
may be outdated and superfluous.  But other implementors likely fallen
into the same traps you did, and reinventing the wheel rarely pays
off.

\subsection{Patching Toplevel Buildsystem}

One last step is necessary before your library gets built as part of
build process.  \GCC has to {\em know} about it.  As it is, you have
to touch \GCC{}'s privates to do it: you need to patch toplevel
\file{configure} and \file{Makefile.def}.  Fortunately, both patches
are trivial.

There is a variable \variable{target\_libraries} in toplevel
\file{configure}.  As the name implies, what libraries get built is
driven by the contents of this variable.  You need to add the name of
your library among the others.

Patching \file{Makefile.def} is more creative task.  This file is used
in concert with \file{Makefile.tpl} by a tool called \literal{autogen}
to produce \file{Makefile.in}.  Inside \file{Makefile.def}, it is
possible to express various inter-library dependencies to define exact
conditions when your library should be built, as well as whether the
library should be installed, bootstrapped, or checked.

@@@TODO if there is time, revisit this section and write some more
about what and how can be defined.@@@

\subsection{Linking the Binaries With Runtime Library}

The method that \GCC uses to decide which runtime libraries to link in
is pretty much a hack: you will inject necessary libraries into the
commandline, before it's processed.

The work is done in \function{lang\_specific\_driver}.  Very general
commandline tweaking can take place here.  The function is given
pointer to \variable{argc} and \variable{argv} variables, and is free
to reorder, add or remove any of the arguments as seems fit.  To
support proper linking, you will want to detect the situation when
your runtime library, \literal{libc}, \literal{libm}, or any other
required library isn't at the commandline yet (or is and shouldn't
be), in which situation you will add or remove it from the vector and
adjust \variable{argc} accordingly.  It's necessary to support native
\GCC switches, such as \option{-nostdlib} and \option{-nodefaultlibs},
as well as your own switches that imply that no linking is to be done
(e.g. \option{-fsyntax-only} or similar).

Unfortunately that implies processing commandline arguments one at a
time, skipping their arguments as necessary (think \option{-o},
\option{-Xlinker}).  It's really not nice solution, but that's the way
it works.

\subsection{Depending on System Libraries}

You may or may not want to depend on system libraries, such as
\literal{libc} or \literal{libm}.  Their handling is mostly the same as
handling your own runtime library, except that you don't have to build
them.

@TODO:maybe move to numerical support chapter:
Since version 4.3.0, \GCC uses \literal{libgmp} to do its constant
folding, which means that the library will be available at compiler
runtime.  Very often that means the library will also be available at
binary run site.  That doesn't hold universally, but at least
\literal{libgmp} was ported to all platforms where \GCC has supported
backends.  What this means for you is that you can dispatch to this
library many numerical algorithms that would otherwise have to be
handrolled or cut'n'pasted.  As far as I know, this is the approach
Fortran fronted is about to take.


\section{Testsuite}

What's dejagnu testsuite, how to write tests, how to integrate them
into GCC testsuite.  You need acurate error reporting to use the
dejagnu GCC framework.  In fortran, they are doing transformations of
error messages to format expected by the framework, describe that.

\section{Debuginfo}

How to add debuginfos to binaries that your frontend produces.  How to
use gdb for your language.

\section{Cross-compilation Issues}

Elaborate on build-host-target trichotomy.  Assure ga60 is
cross-compilation capable and describe what problems there were.

\section{Bootstrapping Issues}

How to write a library in a language whose compiler is built as part
of gcc itself.  How to write a language frontend in language itself.

%=====================================================================%

\chapter{GCC-Specific Language Extensions}

This chapter describes various extensions that you might want to
include to your language.  Not really GCC-only, but GCC supports them.

\section{Attributes}

Employing attributes.  How does frontend handle attributes, how does
it define its own.

\section{Preprocessing}

Employing libcpp.  How to use preprocessor for your language.

\section{Inline Assembly}

Employing assembly.  How to add GCC-compatible inline assembly into
your language.

\section{Open MP}

If the time permits, elaborate on how to use Open MP in frontend.
Look into \cite{GDS:2006:Novillo}.

%=====================================================================%

\chapter{Conclusions}

Conclusions: ``short, concise statements of the inferences that you
have made because of your work. It helps to organize these as short
numbered paragraphs, ordered from most to least important.''

Summary of Contributions: ``The Summary of Contributions will be much
sought and carefully read by the examiners.  Here you list the
contributions of new knowledge that your thesis makes. Of course, the
thesis itself must substantiate any claims made here. There is often
some overlap with the Conclusions, but that's okay. Concise numbered
paragraphs are again best. Organize from most to least important.''

Future Research: How feasible would be to have a frontend, that just
hands all the calls to dynamically loaded external parser?  This would
allow for out-of-tree builds, wouldn't it?

\bibliographystyle{plain}
\bibliography{dp}

\chapter*{Appendix: Frontend-to-Middleend Interface}

Describe all data structures that frontend touches.
http://gcc.gnu.org/projects/documentation.html, project "Fully
document the interface of front ends to GCC"

\chapter*{Appendix: \Algol 60 Compiler}

Installation, supported GCCs, usual stuff.



\chapter{Notes}

Functions need a return statements.  Look how it's done for noreturn
functions.

COND\_EXPR breaks when other value than 0 or 1 is used as condition.


\end{document}

% Local Variables:
% compile-command: "make show-dp"
% End:
